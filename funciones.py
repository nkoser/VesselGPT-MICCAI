import torch
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.optim.lr_scheduler import StepLR
from pathlib import Path


import os
import numpy as np
import Stage1.modelsMultitalk.stage1_vocaset as models
from Stage1.modelsMultitalk.stage1_vocaset import VQAutoEncoder
from Stage1.metrics.loss import calc_vq_loss
from Stage1.base.utilities import AverageMeter

class Args:
    def __init__(self):
        # LOSS settings
        self.quant_loss_weight = 1.

        # NETWORK settings 
        #self.arch = 'stage1_vocaset'
        self.in_dim = 4
        self.hidden_size = 1024
        self.num_hidden_layers = 6
        self.num_attention_heads = 8
        self.intermediate_size = 1536
        self.window_size = 1
        self.quant_factor = 0
        self.face_quan_num = 16
        self.neg = 0.2
        self.INaffine = False

        # Quantization mode
        # legacy: single codebook, split into face_quan_num chunks
        # factorized: multiple codebooks (factor_count) with factor_dim each
        self.quantization_mode = "legacy"
        self.factor_count = 4
        self.factor_dim = 128
        # factor projection: split | linear_shared | linear_per_factor
        self.factor_proj = "split"
        # Optional K-classification head
        self.use_k_head = False
        self.k_loss_weight = 1.0
        self.k_classes = 4

        # VQuantizer settings
        self.n_embed = 256
        self.zquant_dim = 64#64

        # TRAIN settings
        self.batch_size = 1  # batch size for training
        self.batch_size_val = 1  # batch size for validation during training
        self.base_lr = 0.0001
        self.StepLR = True
        self.poly_lr = False
        self.epochs = 50000
        self.step_size = 200
        self.gamma = 0.9


        ##stage 2
        self.device = 'cuda'  # or 'cpu'
        self.feature_dim = 128  # dimension for the feature after audio encoding
        self.vertice_dim = 31  # number of vertices * 3 (e.g., V * 3 for 3D coordinates)
        self.n_head = 8  # number of attention heads in the transformer decoder
        self.num_layers = 6  # number of layers in the transformer decoder
        self.period = 2#100  # period for positional encoding
        self.vqvae_pretrained_path = 'modelos-entrenados/major-oath.pth'  # path to pretrained VQ-VAE

class Tree:

    def __init__(self, data, right = None, left = None):

        self.id = id(self)
        self.data = data

        self.right = right
        self.left = left

def deserialize_post_order(serial):

    serial = serial.copy()

    def post_order(serial):

        if serial[-4:] == [0.0] * 4:
            for i in range(4): serial.pop()
            return None
        
        data = {}

        data["r"] = serial.pop()
        data["z"] = serial.pop()
        data["y"] = serial.pop()
        data["x"] = serial.pop()

        tree = Tree(data)

        tree.right = post_order(serial)
        tree.left = post_order(serial)
        
        return tree    
    
    return post_order(serial)

def deserialize_pre_order(serial):
    
    serial = serial.copy()

    if len(serial) > 0:

        if serial[:4] != [0.0] * 4:
            
            data = {}

            data["x"] = serial.pop(0)
            data["y"] = serial.pop(0)
            data["z"] = serial.pop(0)
            data["r"] = serial.pop(0)

            tree = Tree(data)

            left, ret = deserialize_pre_order(serial)
            right, ret = deserialize_pre_order(ret)

            tree.left = left
            tree.right = right

            return tree, ret

        else:
            return None, serial[4:]
        
    else:
        return None, []

def serialize_pre_order(tree, k):

    if tree == None: return [0.0] * k
    return list(tree.data.values())[::-1] + serialize_pre_order(tree.left) + serialize_pre_order(tree.right)

def serialize_pre_order_kcount(tree, k=4):

    if tree is None:
        return []

    if tree.left is not None and tree.right is not None:
        children = [tree.left, tree.right]
        k_children = 2
    elif tree.left is not None:
        children = [tree.left]
        k_children = 1
    elif tree.right is not None:
        children = [tree.right]
        k_children = 1
    else:
        children = []
        k_children = 0

    if k == 4:
        attrs = [tree.data["x"], tree.data["y"], tree.data["z"], tree.data["r"]]
    else:
        attrs = [tree.data["x"], tree.data["y"], tree.data["z"]] + list(tree.data["r"])

    serial = [float(k_children)] + attrs
    for child in children:
        serial.extend(serialize_pre_order_kcount(child, k))
    return serial

def deserialize(serial, mode = "pre_order"):

    if mode == "pre_order": return deserialize_pre_order(serial)[0]
    if mode == "post_order": return deserialize_post_order(serial)
    if mode in {"pre_order_kcount", "pre_order_k"}:
        return deserialize_pre_order_kcount(serial)[0]
    if mode in {"pre_order_kdir", "pre_order_k_lr"}:
        return deserialize_pre_order_kdir(serial)[0]

    print("UNSUPPORTED DESERIALIZATION MODE")

def deserialize_pre_order_kcount(serial, k=4):

    serial = serial.copy()

    def parse(seq):
        if len(seq) < 1 + k:
            return None, seq

        k_children = int(seq.pop(0))

        data = {
            "x": seq.pop(0),
            "y": seq.pop(0),
            "z": seq.pop(0),
        }
        if k == 4:
            data["r"] = seq.pop(0)
        else:
            data["r"] = [seq.pop(0) for _ in range(k - 3)]

        tree = Tree(data)

        if k_children == 0:
            return tree, seq
        if k_children >= 1:
            left, seq = parse(seq)
            tree.left = left
        if k_children >= 2:
            right, seq = parse(seq)
            tree.right = right

        return tree, seq

    return parse(serial)

def serialize_pre_order_kdir(tree, k=4):

    if tree is None:
        return []

    if tree.left is not None and tree.right is not None:
        children = [tree.left, tree.right]
        k_children = 3
    elif tree.left is not None:
        children = [tree.left]
        k_children = 1
    elif tree.right is not None:
        children = [tree.right]
        k_children = 2
    else:
        children = []
        k_children = 0

    if k == 4:
        attrs = [tree.data["x"], tree.data["y"], tree.data["z"], tree.data["r"]]
    else:
        attrs = [tree.data["x"], tree.data["y"], tree.data["z"]] + list(tree.data["r"])

    serial = [float(k_children)] + attrs
    for child in children:
        serial.extend(serialize_pre_order_kdir(child, k))
    return serial

def deserialize_pre_order_kdir(serial, k=4):

    serial = serial.copy()

    def parse(seq):
        if len(seq) < 1 + k:
            return None, seq

        k_children = int(seq.pop(0))

        data = {
            "x": seq.pop(0),
            "y": seq.pop(0),
            "z": seq.pop(0),
        }
        if k == 4:
            data["r"] = seq.pop(0)
        else:
            data["r"] = [seq.pop(0) for _ in range(k - 3)]

        tree = Tree(data)

        if k_children == 0:
            return tree, seq
        if k_children in (1, 3):
            left, seq = parse(seq)
            tree.left = left
        if k_children in (2, 3):
            right, seq = parse(seq)
            tree.right = right

        return tree, seq

    return parse(serial)
    
class IntraDataset(Dataset):

    def __init__(self, file_list, root_dir, mode = "pre_order", p = None, val = False):

        
        #self.folder_path = folder_path
        #self.file_list = os.listdir(folder_path)  # Call os.listdir only once
        self.mode = mode
        self.root_dir = Path(root_dir)
        self.file_list = []
        self.val = val
        for rel_path in file_list:
            if p is not None:
                full_path = self.root_dir / f"p{p}" / rel_path
            else:
                full_path = self.root_dir / rel_path
            self.file_list.append(str(full_path))
        
        # Split dataset for train and validation
        total_files = len(self.file_list)
       
        print("Dataset size:", len(self))

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):

        file_path = self.file_list[idx]

        # Use memory mapping to avoid loading full file into memory
        tree_data_np = np.load(file_path, mmap_mode='r')
        
        # Convert to tensor only when accessed
        tree_tensor = torch.tensor(tree_data_np, dtype=torch.float32)
        if tree_tensor.dim() == 2:
            file_dim = tree_tensor.shape[1]
        else:
            file_dim = None
        if file_dim is None:
            if self.mode in {"pre_order_kcount", "pre_order_k", "pre_order_kdir", "pre_order_k_lr"}:
                file_dim = 40 if (tree_tensor.numel() % 40 == 0) else 39
            else:
                file_dim = 39
        tree_tensor = tree_tensor.reshape((-1, file_dim))

        if self.mode == "pre_order":

            serial_tree = list(tree_tensor.flatten().numpy())

            print(len(serial_tree))

            tree = deserialize(serial_tree, mode = "post_order")
            serial_tree = serialize_pre_order(tree, k=39)
            np_tree = np.array(serial_tree).reshape((-1,39))
            tree_tensor = torch.tensor(np_tree, dtype = torch.float32)

        if self.mode in {"pre_order_kcount", "pre_order_k"}:

            if file_dim == 40:
                return tree_tensor if not self.val else (tree_tensor, file_path)
            serial_tree = list(tree_tensor.flatten().numpy())
            tree = deserialize(serial_tree, mode="post_order")
            serial_tree = serialize_pre_order_kcount(tree, k=39)
            np_tree = np.array(serial_tree).reshape((-1, 40))
            tree_tensor = torch.tensor(np_tree, dtype=torch.float32)

        if self.mode in {"pre_order_kdir", "pre_order_k_lr"}:

            if file_dim == 40:
                return tree_tensor if not self.val else (tree_tensor, file_path)
            serial_tree = list(tree_tensor.flatten().numpy())
            tree = deserialize(serial_tree, mode="post_order")
            serial_tree = serialize_pre_order_kdir(tree, k=39)
            np_tree = np.array(serial_tree).reshape((-1, 40))
            tree_tensor = torch.tensor(np_tree, dtype=torch.float32)

            
        if not self.val:
            return tree_tensor
        else:
            return tree_tensor, file_path


def save_best_model(model, optimizer, epoch, loss, best_loss, model_save_path="best_model.pth"):
    """
    Save the model if the current loss is better than the best recorded loss.
    
    Args:
        model (torch.nn.Module): The model being trained.
        optimizer (torch.optim.Optimizer): The optimizer used in training.
        epoch (int): The current epoch number.
        loss (float): The current epoch's loss.
        best_loss (float): The best loss recorded so far.
        model_save_path (str): Path to save the best model.
    
    Returns:
        float: The updated best loss (could be the same or updated if the model improved).
    """
    if loss < best_loss:
        #print(f"Epoch [{epoch+1}], New best model found! Loss: {loss:.4f}")
        best_loss = loss
        
        # Save the model
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': loss,
        }, model_save_path)

    return best_loss

def save_best_model_gpt2(model, optimizer, epoch, loss, best_loss, model_save_path):
    """
    Save the model if the current loss is better than the best recorded loss.
    
    Args:
        model (torch.nn.Module): The model being trained.
        optimizer (torch.optim.Optimizer): The optimizer used in training.
        epoch (int): The current epoch number.
        loss (float): The current epoch's loss.
        best_loss (float): The best loss recorded so far.
        model_save_path (str): Path to save the best model.
    
    Returns:
        float: The updated best loss (could be the same or updated if the model improved).
    """
    if loss < best_loss:
        #print(f"Epoch [{epoch+1}], New best model found! Loss: {loss:.4f}")
        best_loss = loss
        
        # Save the model
        model.save_pretrained(model_save_path)
        
    return best_loss

import os

def erase_all_files(folder_path):

    # Iterate through all items in the folder

    for filename in os.listdir(folder_path):

        file_path = os.path.join(folder_path, filename)
        if os.path.isfile(file_path): os.remove(file_path)
