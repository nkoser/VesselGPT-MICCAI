{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from Stage1.modelsMultitalk.stage1_vocaset import VQAutoEncoder\n",
    "from Stage1.metrics.loss import calc_vq_loss\n",
    "from Stage1.base.utilities import AverageMeter\n",
    "import wandb\n",
    "from funciones import IntraDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        # LOSS settings\n",
    "        self.quant_loss_weight = 1.\n",
    "\n",
    "        # NETWORK settings\n",
    "        #self.arch = 'stage1_vocaset'\n",
    "        self.in_dim = 39\n",
    "        self.hidden_size = 1024\n",
    "        self.num_hidden_layers = 6\n",
    "        self.num_attention_heads = 8\n",
    "        self.intermediate_size = 1536\n",
    "        self.window_size = 1\n",
    "        self.quant_factor = 0\n",
    "        self.face_quan_num = 16\n",
    "        self.neg = 0.2\n",
    "        self.INaffine = False \n",
    "\n",
    "        # VQuantizer settings\n",
    "        self.n_embed = 256\n",
    "        self.zquant_dim = 64#64\n",
    "\n",
    "        # TRAIN settings\n",
    "        self.use_sgd = False\n",
    "        self.sync_bn = False  # adopt sync_bn or not\n",
    "        self.train_gpu = [0]\n",
    "        self.workers = 10  # data loader workers\n",
    "        self.batch_size = 1  # batch size for training\n",
    "        self.batch_size_val = 1  # batch size for validation during training\n",
    "        self.base_lr = 0.0001\n",
    "        self.StepLR = True\n",
    "        self.warmup_steps = 1\n",
    "        self.adaptive_lr = False\n",
    "        self.factor = 0.3\n",
    "        self.patience = 3\n",
    "        self.threshold = 0.0001\n",
    "        self.poly_lr = False\n",
    "        self.epochs = 200\n",
    "        self.step_size = 200\n",
    "        self.gamma = 0.9\n",
    "        self.start_epoch = 0\n",
    "        self.power = 0.9\n",
    "        self.momentum = 0.9\n",
    "        self.weight_decay = 0.002\n",
    "        self.manual_seed = 131\n",
    "\n",
    "        ##stage 2\n",
    "        self.device = 'cuda'  # or 'cpu'\n",
    "        self.dataset = 'BIWI'  # or 'multi' depending on your dataset\n",
    "        self.wav2vec2model_path = 'path/to/wav2vec2model'  # path to pretrained Wav2Vec2 model\n",
    "        self.feature_dim = 1024  # dimension for the feature after audio encoding\n",
    "        self.vertice_dim = 31  # number of vertices * 3 (e.g., V * 3 for 3D coordinates)\n",
    "        self.n_head = 8  # number of attention heads in the transformer decoder\n",
    "        self.num_layers = 6  # number of layers in the transformer decoder\n",
    "        self.period = 2#100  # period for positional encoding\n",
    "        #self.face_quan_num = 16  # quantization levels per face/vertex\n",
    "        #self.zquant_dim = 64  # dimension of the quantized latent space\n",
    "        self.vqvae_pretrained_path = 'modelos-entrenados/fast-bee.pth'  # path to pretrained VQ-VAE\n",
    "        self.train_subjects = 'subject1 subject2 subject3'  # space-separated list of subjects used in training\n",
    "        self.motion_weight = 1.0  # weight for the motion loss\n",
    "        self.reg_weight = 0.1  # weight for the regularization loss\n",
    "        self.batch_size = 1#32  # batch size for training\n",
    "        #self.epochs = 100  # number of training epochs\n",
    "        #self.base_lr = 0.0001  # base learning rate\n",
    "        self.gpu = torch.cuda.current_device()\n",
    "\n",
    "# Instantiate the arguments\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hidden_size = face_quan_num *   self.zquant_dim = 64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(args.face_quan_num *  args.zquant_dim )\n",
    "print(args.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 415\n",
      "Dataset size: 52\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "INTRA_FOLDER = \"Data/AneuxSplines/zero-root/p15/train/\"\n",
    "intra_dataset = IntraDataset(INTRA_FOLDER, mode=\"post_order\") #mode es el modo al que quiero que transforme\n",
    "data_loader = DataLoader(intra_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "#dataset de validacion\n",
    "VAL_FOLDER = \"Data/AneuxSplines/zero-root/p15/val/\"\n",
    "\n",
    "val_dataset = IntraDataset(VAL_FOLDER, mode = \"post_order\")\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_loader, model, loss_fn, epoch, cfg):\n",
    "    accumulated_loss = 0\n",
    "    accumulated_rec = 0\n",
    "    accumulated_quant = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs in val_loader:\n",
    "            \n",
    "            inputs= inputs.to(device)\n",
    "            if inputs.shape[1] > 1:\n",
    "                out, quant_loss, info = model(inputs)\n",
    "                \n",
    "                # LOSS\n",
    "                loss, loss_details = loss_fn(out, inputs, quant_loss, quant_loss_weight=cfg.quant_loss_weight)\n",
    "                accumulated_loss += loss\n",
    "                accumulated_rec += loss_details[0]\n",
    "                accumulated_quant += loss_details[1]\n",
    "        \n",
    "\n",
    "        # Calculate the average loss over the entire dataset\n",
    "        avg_loss = accumulated_loss / len(val_loader)\n",
    "        rec_loss = accumulated_rec / len(val_loader)\n",
    "        quant_loss = accumulated_quant / len(val_loader)\n",
    "\n",
    "            \n",
    "\n",
    "    return avg_loss, rec_loss, quant_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpaufeldman\u001b[0m (\u001b[33mvesselgpt\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\lab03\\_netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(anonymous=\"must\")\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\lab03\\Documents\\VesselGPTClean\\wandb\\run-20250609_145616-4z1zbyz2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vesselgpt/vqvae-mesh/runs/4z1zbyz2?apiKey=2511bccb1c20c8149e91d2ff7ad5b57fab7df870' target=\"_blank\">exalted-planet-126</a></strong> to <a href='https://wandb.ai/vesselgpt/vqvae-mesh?apiKey=2511bccb1c20c8149e91d2ff7ad5b57fab7df870' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vesselgpt/vqvae-mesh?apiKey=2511bccb1c20c8149e91d2ff7ad5b57fab7df870' target=\"_blank\">https://wandb.ai/vesselgpt/vqvae-mesh?apiKey=2511bccb1c20c8149e91d2ff7ad5b57fab7df870</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vesselgpt/vqvae-mesh/runs/4z1zbyz2?apiKey=2511bccb1c20c8149e91d2ff7ad5b57fab7df870' target=\"_blank\">https://wandb.ai/vesselgpt/vqvae-mesh/runs/4z1zbyz2?apiKey=2511bccb1c20c8149e91d2ff7ad5b57fab7df870</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Do NOT share these links with anyone. They can be used to claim your runs."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vesselgpt/vqvae-mesh/runs/4z1zbyz2?apiKey=2511bccb1c20c8149e91d2ff7ad5b57fab7df870?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x29650145710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"vqvae-mesh\", config=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_best_model(model, optimizer, epoch, loss, best_loss, model_save_path=\"best_model.pth\"):\n",
    "    \"\"\"\n",
    "    Save the model if the current loss is better than the best recorded loss.\n",
    "    \n",
    "    Args:\n",
    "        model (torch.nn.Module): The model being trained.\n",
    "        optimizer (torch.optim.Optimizer): The optimizer used in training.\n",
    "        epoch (int): The current epoch number.\n",
    "        loss (float): The current epoch's loss.\n",
    "        best_loss (float): The best loss recorded so far.\n",
    "        model_save_path (str): Path to save the best model.\n",
    "    \n",
    "    Returns:\n",
    "        float: The updated best loss (could be the same or updated if the model improved).\n",
    "    \"\"\"\n",
    "    if loss < best_loss:\n",
    "        #print(f\"Epoch [{epoch+1}], New best model found! Loss: {loss:.4f}\")\n",
    "        best_loss = loss\n",
    "        \n",
    "        # Save the model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "        }, model_save_path)\n",
    "    return best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 100856871\n",
      "Epoch [1/500000], Total Loss: 4.2408, Rec Loss: 0.19139, Quant Loss: 4.04944, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [2/500000], Total Loss: 2.2972, Rec Loss: 0.09397, Quant Loss: 2.20319, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [3/500000], Total Loss: 1.3421, Rec Loss: 0.06938, Quant Loss: 1.27268, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [4/500000], Total Loss: 0.8515, Rec Loss: 0.06097, Quant Loss: 0.79050, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [5/500000], Total Loss: 0.6081, Rec Loss: 0.05276, Quant Loss: 0.55538, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [6/500000], Total Loss: 0.4639, Rec Loss: 0.04850, Quant Loss: 0.41543, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [7/500000], Total Loss: 0.3821, Rec Loss: 0.04675, Quant Loss: 0.33539, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [8/500000], Total Loss: 0.3300, Rec Loss: 0.04316, Quant Loss: 0.28687, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [9/500000], Total Loss: 0.2904, Rec Loss: 0.04170, Quant Loss: 0.24865, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [10/500000], Total Loss: 0.2648, Rec Loss: 0.03985, Quant Loss: 0.22493, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [11/500000], Total Loss: 0.2409, Rec Loss: 0.03840, Quant Loss: 0.20251, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [12/500000], Total Loss: 0.2262, Rec Loss: 0.03944, Quant Loss: 0.18674, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [13/500000], Total Loss: 0.2143, Rec Loss: 0.03798, Quant Loss: 0.17632, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [14/500000], Total Loss: 0.2017, Rec Loss: 0.03700, Quant Loss: 0.16470, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [15/500000], Total Loss: 0.1912, Rec Loss: 0.03551, Quant Loss: 0.15573, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [16/500000], Total Loss: 0.1836, Rec Loss: 0.03570, Quant Loss: 0.14790, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [17/500000], Total Loss: 0.1725, Rec Loss: 0.03455, Quant Loss: 0.13798, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [18/500000], Total Loss: 0.1680, Rec Loss: 0.03527, Quant Loss: 0.13277, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [19/500000], Total Loss: 0.1590, Rec Loss: 0.03360, Quant Loss: 0.12542, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [20/500000], Total Loss: 0.1494, Rec Loss: 0.03247, Quant Loss: 0.11695, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [21/500000], Total Loss: 0.1441, Rec Loss: 0.03298, Quant Loss: 0.11113, Perplexity: 0.0000, Learning Rate: 0.000100\n",
      "Epoch [22/500000], Total Loss: 0.1334, Rec Loss: 0.03234, Quant Loss: 0.10108, Perplexity: 0.0000, Learning Rate: 0.000100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 64\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[38;5;66;03m# Update meters and track individual components\u001b[39;00m\n\u001b[0;32m     59\u001b[0m         \u001b[38;5;66;03m#for m, x in zip([rec_loss_meter, quant_loss_meter, pp_meter],\u001b[39;00m\n\u001b[0;32m     60\u001b[0m         \u001b[38;5;66;03m#                [loss_details[0], loss_details[1], info[0]]):\u001b[39;00m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m#    m.update(x.item(), 1)\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m m, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m([rec_loss_meter, quant_loss_meter, total_loss_meter],\n\u001b[0;32m     63\u001b[0m                     [loss_details[\u001b[38;5;241m0\u001b[39m], loss_details[\u001b[38;5;241m1\u001b[39m], loss]):\n\u001b[1;32m---> 64\u001b[0m             m\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m#accum  /= len(data_loader)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m#optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#loss.backward()\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#optimizer.step()\u001b[39;00m\n\u001b[0;32m     72\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), max_norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Sample training loop\n",
    "num_epochs = 500000  # Define number of epochs\n",
    "best_loss = float('inf')  # Initialize to a very high value\n",
    "\n",
    "model = VQAutoEncoder(args)\n",
    "\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=args.base_lr)\n",
    "#scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: max(1e-4, min(1.0, epoch / 100)))\n",
    "scheduler = StepLR(optimizer, step_size=args.step_size, gamma=args.gamma)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Total number of parameters: {total_params}\")\n",
    "\n",
    "rec_loss_list = []\n",
    "quant_loss_list = []\n",
    "pp_list = []\n",
    "total_loss_list = []\n",
    "\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "initial_quant_loss_weight = 100.0  # Starting weight for quantization loss\n",
    "final_quant_loss_weight = 2.     # Final weight for quantization loss        \n",
    "decay_epochs = 300\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    rec_loss_meter = AverageMeter()\n",
    "    quant_loss_meter = AverageMeter()\n",
    "    total_loss_meter = AverageMeter()\n",
    "    pp_meter = AverageMeter()\n",
    "    accum = 0\n",
    "    for inputs in data_loader:\n",
    "        \n",
    "        inputs = inputs.to(device)\n",
    "        if inputs.shape[1] > 1:\n",
    "            out, quant_loss, info = model(inputs)\n",
    "            \n",
    "\n",
    "            #out= model(inputs) ##para entrenar sin cuantizar\n",
    "\n",
    "            #current_quant_loss_weight = initial_quant_loss_weight - (initial_quant_loss_weight - final_quant_loss_weight) * (epoch / decay_epochs)\n",
    "            # Calculate loss\n",
    "            loss, loss_details = calc_vq_loss(out, inputs, quant_loss=quant_loss, quant_loss_weight=args.quant_loss_weight)\n",
    "            if torch.isnan(loss):\n",
    "                breakpoint()\n",
    "            #loss, loss_details = calc_vq_loss(out, inputs, quant_loss, quant_loss_weight=current_quant_loss_weight, current_epoch = epoch)\n",
    "            \n",
    "            #############\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            #accum += loss\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            for m, x in zip([rec_loss_meter, quant_loss_meter, total_loss_meter],\n",
    "                        [loss_details[0], loss_details[1], loss]):\n",
    "                m.update(x.item(), 1)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "    avg_loss_val, rec_loss_val, quant_loss_val = validate(val_loader, model, calc_vq_loss, epoch, args)\n",
    "    # Append averaged losses after each epoch\n",
    "    rec_loss = rec_loss_meter.avg\n",
    "    quant_loss = quant_loss_meter.avg\n",
    "    total_loss = total_loss_meter.avg #aca tengo la total loss promedio de la epoch\n",
    "    \n",
    "    wandb.log({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Reconstruction Loss\": rec_loss,\n",
    "        \"Quantization Loss\": quant_loss,\n",
    "        \"Total Loss\": total_loss,\n",
    "        \"Total loss val\": avg_loss_val,\n",
    "        \"Reconstruction loss val\": rec_loss_val,\n",
    "        \"Quantization loss val\": quant_loss_val,\n",
    "        \"Learning Rate\": optimizer.param_groups[0]['lr']\n",
    "    })\n",
    "    # Append to respective lists\n",
    "    rec_loss_list.append(rec_loss)\n",
    "    quant_loss_list.append(quant_loss)\n",
    "\n",
    "    \n",
    "    best_loss = save_best_model(model, optimizer, epoch, rec_loss_val, best_loss, \"models/stage1/aneux/best-model-aneux15-zero-root.pth\")\n",
    "\n",
    "    # Print learning rate and losses every 10 epochs\n",
    "    if epoch % 1 == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Total Loss: {total_loss:.4f}, Rec Loss: {rec_loss:.5f}, Quant Loss: {quant_loss:.5f}, Perplexity: {pp_meter.avg:.4f}, Learning Rate: {current_lr:.6f}\")\n",
    "        #print(f\"Epoch [{epoch+1}/{num_epochs}], Total Loss: {loss:.4f}, Learning Rate: {current_lr:.8f}\")\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "    if epoch == 280:\n",
    "        # Reinitialize with a larger step size\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
