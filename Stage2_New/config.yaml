paths:
  train_dir: ../Preprocessing_modular/DemoOutput/TreesSplines_20depth_tokens/train
  val_dir: ../Preprocessing_modular/DemoOutput/TreesSplines_20depth_tokens/val
  output_dir: Stage2_New/output_02
  best_model_dir: Stage2_New/output/best-gpt2

params:
  vocab_size: 259
  max_size: 2258
  pad_token: 257
  eos_token: 256
  epochs: 50000
  lr: 0.0001
  batch_size: 4
  shuffle: false
  warmup_steps: 0
  scheduler: linear
  seed: 12
  device: 0
  log_every: 1
  track_token_usage: false
  token_usage_exclude_ids: []

model:
  n_embd: 512
  n_layer: 6
  n_head: 8

wandb:
  enabled: true
  project: gpt2
  #entity: vesselgpt
  mode: online
  run_name: first_run_stage2_new_01
